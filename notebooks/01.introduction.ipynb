{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"NONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure your environmental variables and dependencies are ready to use LLM services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env_api\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In langrila, the module to chat with LLM and the module to call tools are completely separated. FunctionalChat class is the combination of those two.\n",
    "\n",
    "- `XXXChatModule`: Only focuses on doing conversation with LLM\n",
    "- `XXXFunctionCallingModule`: Only focuses on calling tools\n",
    "- `XXXFunctionalChat`: The combination of the two. FunctionCallingModule works at first and then ChatModule performs. If any tool is not provided, this module behaves as just ChatModule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langrila import (\n",
    "    InMemoryConversationMemory,\n",
    "    Message,\n",
    "    PromptTemplate,\n",
    "    Usage,\n",
    ")\n",
    "from langrila.claude import ClaudeFunctionalChat\n",
    "from langrila.gemini import GeminiFunctionalChat\n",
    "from langrila.openai import OpenAIFunctionalChat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple text prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For OpenAI Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_openai = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"API_KEY\",\n",
    "    model_name=\"gpt-4o-2024-05-13\",\n",
    "    api_type=\"openai\",\n",
    "    # organization_id_env_name=\"ORGANIZATION_ID\",  # as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hello. How are you today?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate synchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_openai.run(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "response is a pydantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': {'role': 'assistant',\n",
       "  'content': [{'text': \"Hello! I'm just a computer program, so I don't have feelings, but thank you for asking. How can I assist you today?\"}],\n",
       "  'name': None},\n",
       " 'usage': {'model_name': 'gpt-4o-2024-05-13',\n",
       "  'prompt_tokens': 16,\n",
       "  'completion_tokens': 27},\n",
       " 'prompt': [{'role': 'user',\n",
       "   'content': [{'type': 'text', 'text': 'Hello. How are you today?'}],\n",
       "   'name': 'User'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pick response text like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but thank you for asking. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see usage to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=16, completion_tokens=27, total_tokens=43)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': [{'type': 'text', 'text': 'Hello. How are you today?'}],\n",
       "  'name': 'User'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous call is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm here and ready to help you with whatever you need. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = await chat_openai.arun(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello!')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you.\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=16, completion_tokens=30, total_tokens=46), prompt=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Hello. How are you today?'}], 'name': 'User'}])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = chat_openai.stream(prompt)\n",
    "responses = [r for r in stream]\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last response includes usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=16, completion_tokens=30, total_tokens=46)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[-1].usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello!')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to assist\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to assist you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to assist you.\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to assist you. How\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to assist you. How can\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to assist you. How can I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to assist you. How can I help\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to assist you. How can I help you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to assist you. How can I help you today\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to assist you. How can I help you today?\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to assist you. How can I help you today?\")], name=None), usage=Usage(prompt_tokens=16, completion_tokens=17, total_tokens=33), prompt=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Hello. How are you today?'}], 'name': 'User'}])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = chat_openai.astream(prompt)\n",
    "responses = [r async for r in stream]\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_openai.run(prompt, n_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"Hello! I'm here and ready to help you. How can I assist you today?\"},\n",
       "  {'text': \"Hello! I'm just a machine, so I don't have feelings, but thank you for asking. How can I assist you today?\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist you today?\"},\n",
       "  {'text': \"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# async\n",
    "\n",
    "response = await chat_openai.arun(prompt, n_results=2)\n",
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_openai_azure = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"AZURE_API_KEY\",\n",
    "    model_name=\"gpt-4o-2024-05-13\",\n",
    "    api_type=\"azure\",\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    endpoint_env_name=\"AZURE_ENDPOINT\",\n",
    "    deployment_id_env_name=\"AZURE_DEPLOYMENT_ID\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response = chat_openai_azure.run(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with anything you need. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# async\n",
    "response = await chat_openai_azure.arun(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello!')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or information\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or information you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or information you need\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or information you need.\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or information you need. How\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or information you need. How can\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or information you need. How can I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or information you need. How can I assist\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or information you need. How can I assist you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or information you need. How can I assist you today\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or information you need. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or information you need. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=15, completion_tokens=44, total_tokens=59), prompt=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Hello. How are you today?'}], 'name': 'User'}])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stream\n",
    "response = chat_openai_azure.stream(prompt)\n",
    "[r for r in response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello!')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you.\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}]),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=15, completion_tokens=37, total_tokens=52), prompt=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Hello. How are you today?'}], 'name': 'User'}])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# async stream\n",
    "response = chat_openai_azure.astream(prompt)\n",
    "[r async for r in response]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"Hello! I'm just a computer program, so I don't have feelings, but thank you for asking. How can I assist you today?\"},\n",
       "  {'text': \"Hello! I'm an AI, so I don't have feelings, but thanks for asking. How can I assist you today?\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat_openai_azure.run(prompt, n_results=2)\n",
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"Hello! I'm here and ready to help you. How can I assist you today?\"},\n",
       "  {'text': \"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist you today?\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# async\n",
    "response = await chat_openai_azure.arun(prompt, n_results=2)\n",
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini on Google Generative AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = GeminiFunctionalChat(\n",
    "    api_key_env_name=\"GEMINI_API_KEY\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I don't have feelings or experiences like humans do, so I don't have \"good\" or \"bad\" days. But I'm here and ready to assist you with any questions or tasks you may have!  ðŸ˜Š How can I help you today? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = gemini.run(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': 'As an AI, I don\\'t have feelings or experiences like humans do, so I don\\'t have \"good\" or \"bad\" days. But I\\'m here and ready to assist you with any questions or tasks you may have!  ðŸ˜Š How can I help you today? \\n'}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I don't have feelings or experiences like humans do, so I don't have a \"day\" in the same way.  But I'm ready to help you with anything you need! ðŸ˜Š What can I do for you today? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# async\n",
    "response = await gemini.arun(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='As')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do.  \")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do.  But I'm here and ready to assist you! ðŸ˜Š  How can I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do.  But I'm here and ready to assist you! ðŸ˜Š  How can I help you today? \\n\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do.  But I'm here and ready to assist you! ðŸ˜Š  How can I help you today? \\n\")], name=None), usage=Usage(prompt_tokens=8, completion_tokens=39, total_tokens=47), prompt=[parts {\n",
       "   text: \"Hello. How are you today?\"\n",
       " }\n",
       " role: \"user\"\n",
       " ])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stream\n",
    "response = gemini.stream(prompt)\n",
    "[r for r in response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='As')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do. So\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do. So, I\\'m not \"feeling\" anything! But I\\'m ready to')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do. So, I\\'m not \"feeling\" anything! But I\\'m ready to assist you with whatever you need. How can I help you today? ðŸ˜Š \\n')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do. So, I\\'m not \"feeling\" anything! But I\\'m ready to assist you with whatever you need. How can I help you today? ðŸ˜Š \\n')], name=None), usage=Usage(prompt_tokens=8, completion_tokens=50, total_tokens=58), prompt=[parts {\n",
       "   text: \"Hello. How are you today?\"\n",
       " }\n",
       " role: \"user\"\n",
       " ])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# async stream\n",
    "response = gemini.astream(prompt)\n",
    "[r async for r in response]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini on VertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_vertexai = GeminiFunctionalChat(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    api_type=\"vertexai\",\n",
    "    project_id_env_name=\"PROJECT_ID\",\n",
    "    location_env_name=\"LOCATION\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I don't have feelings or experiences like humans do. However, I'm here and ready to assist you with any questions or tasks you may have! ðŸ˜Š  How can I help you today? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = gemini_vertexai.run(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI, so I don't have feelings or experiences like humans do. But I am ready to help you with anything you need! ðŸ˜Š What can I do for you today? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# async\n",
    "response = await gemini_vertexai.arun(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='As')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do. However\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do. However, I'm here and ready to assist you with any questions or tasks you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do. However, I'm here and ready to assist you with any questions or tasks you may have! ðŸ˜Š \\n\\nHow can I help you today? \\n\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do. However, I'm here and ready to assist you with any questions or tasks you may have! ðŸ˜Š \\n\\nHow can I help you today? \\n\")], name=None), usage=Usage(prompt_tokens=7, completion_tokens=48, total_tokens=55), prompt=[role: \"user\"\n",
       " parts {\n",
       "   text: \"Hello. How are you today?\"\n",
       " }\n",
       " ])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stream\n",
    "response = gemini_vertexai.stream(prompt)\n",
    "[r for r in response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='As')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do. So\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do. So, I\\'m not \"good\" or \"bad\" today. I\\'')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do. So, I\\'m not \"good\" or \"bad\" today. I\\'m here to assist you! How can I help you today? ðŸ˜Š \\n')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=''),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do. So, I\\'m not \"good\" or \"bad\" today. I\\'m here to assist you! How can I help you today? ðŸ˜Š \\n')], name=None), usage=Usage(prompt_tokens=7, completion_tokens=49, total_tokens=56), prompt=[role: \"user\"\n",
       " parts {\n",
       "   text: \"Hello. How are you today?\"\n",
       " }\n",
       " ])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# async stream\n",
    "response = gemini_vertexai.astream(prompt)\n",
    "[r async for r in response]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple resposne generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = gemini_vertexai.run(prompt, n_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': 'As a large language model, I don\\'t have feelings or experiences like humans do. So, I\\'m not \"feeling\" anything in particular today. ðŸ˜Š \\n\\nHow are *you* doing today? ðŸ˜Š \\n'},\n",
       "  {'text': 'As a large language model, I don\\'t have feelings or experiences like humans do. So, I\\'m not \"feeling\" anything in particular today. ðŸ˜Š \\n\\nHow are *you* doing today? ðŸ˜Š \\n'}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"As an AI, I don't have feelings or experiences like humans do. However, I'm here and ready to assist you with any questions or tasks you may have! ðŸ˜Š How can I help you today? \\n\"},\n",
       "  {'text': \"As an AI, I don't have feelings or experiences like humans do. However, I'm here and ready to assist you with any questions or tasks you may have! ðŸ˜Š How can I help you today? \\n\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# async multiple generation\n",
    "response = await gemini_vertexai.arun(prompt, n_results=2)\n",
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Claude on Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = ClaudeFunctionalChat(\n",
    "    model_name=\"claude-3-5-sonnet-20240620\",\n",
    "    api_key_env_name=\"ANTHROPIC_API_KEY\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready to assist you with any questions or tasks you might have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response = claude.run(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready to assist you with any questions or tasks you may have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# async\n",
    "response = await claude.arun(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming generation have not been supported yet by Claude in langrila."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Claude on Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_bedrock = ClaudeFunctionalChat(\n",
    "    model_name=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    api_type=\"bedrock\",\n",
    "    aws_access_key_env_name=\"AWS_ACCESS_KEY\",\n",
    "    aws_secret_key_env_name=\"AWS_SECRET_KEY\",\n",
    "    aws_region_env_name=\"AWS_REGION\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! As an AI language model, I don't have personal feelings, but I'm operating properly and ready to assist you with any questions or tasks you may have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response = claude_bedrock.run(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! As an AI language model, I don't have feelings or emotions, but I'm operating properly and ready to assist you with any questions or tasks you may have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response = await claude_bedrock.arun(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal message system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langrila's chat module transforms user prompt and conversation history to universal message object at first, then converts to each client message. Conversation memory has history with universal message format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Please describe this picture.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting from prompt to universal message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='user', content=[TextContent(text='Please describe this picture.')], name=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langrila.openai import OpenAIMessage\n",
    "\n",
    "universal_message = OpenAIMessage.to_universal_message(role=\"user\", message=prompt)\n",
    "universal_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting from universal message to client message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': [{'type': 'text', 'text': 'Please describe this picture.'}],\n",
       " 'name': 'User'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OpenAIMessage.to_client_message(universal_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini module has same interface. Also Claude as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='user', content=[TextContent(text='Please describe this picture.')], name=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langrila.gemini.genai import GeminiMessage\n",
    "\n",
    "# same method as that of OpenAIMessage\n",
    "universal_message = GeminiMessage.to_universal_message(role=\"user\", message=prompt)\n",
    "universal_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parts {\n",
       "  text: \"Please describe this picture.\"\n",
       "}\n",
       "role: \"user\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GeminiMessage.to_client_message(universal_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to set a role and name for your prompt, Message class allows you to do it. Raw text prompt is converted to TextContent object in langrila's chat modules, so TextContent object also can be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='user', content='Hello.', name='Nsak')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = Message(role=\"user\", content=\"Hello.\", name=\"Nsak\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing universal message class, we can use OpenAI Chat Completion, Gemini and Claude in a same way and connect them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversation memory allows you to interact with modules for multi-turn conversation.\n",
    "shared_memory = InMemoryConversationMemory()\n",
    "\n",
    "gemini = GeminiFunctionalChat(\n",
    "    api_key_env_name=\"GEMINI_API_KEY\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    conversation_memory=shared_memory,\n",
    ")\n",
    "\n",
    "chat_openai = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"API_KEY\",\n",
    "    model_name=\"gpt-4o-2024-05-13\",\n",
    "    api_type=\"openai\",\n",
    "    conversation_memory=shared_memory,\n",
    ")\n",
    "\n",
    "claude = ClaudeFunctionalChat(\n",
    "    model_name=\"claude-3-5-sonnet-20240620\",\n",
    "    api_key_env_name=\"ANTHROPIC_API_KEY\",\n",
    "    conversation_memory=shared_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call OpenAI Chat Completion at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Rude is a character in the video game *Final Fantasy VII*. He is a member of the Turks, a covert group working for the Shinra Electric Power Company. Distinguished by his bald head, sunglasses, and silent demeanor, Rude is known for being a skilled fighter and loyal teammate. Throughout the game, players encounter Rude multiple times in various battles and story events, where he often acts alongside his partner Reno. Despite working for Shinra, Rude, along with other members of the Turks, is portrayed with a level of depth that reveals his own sense of honor and camaraderie.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Do you know Rude in Final Fantasy VII?\"\n",
    "response = chat_openai.run(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calling OpenAI Chat Completion, conversation history is inherited by Gemini as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's tricky to pinpoint exactly what Rude thinks of Tifa. There's no direct dialogue in *Final Fantasy VII* revealing his inner thoughts about her. However, we can piece together some clues from his interactions and behavior:\n",
      "\n",
      "* **Respect as an opponent:** Rude, being a professional, likely respects Tifa's strength and fighting ability. He wouldn't underestimate her, as seen in their encounters, especially during the battle at the Shinra building.\n",
      "* **Potential intrigue:** Given the Turks' role as gatherers of information, he might find her background and connection to Cloud intriguing. He might see her as a potential threat or someone to be watched.\n",
      "* **Professional distance:** As a member of Shinra, Rude wouldn't be inclined to show personal feelings towards anyone opposing the company. He would likely maintain a neutral and professional demeanor around Tifa.\n",
      "\n",
      "In essence, Rude probably views Tifa as a competent and dangerous opponent, someone worthy of respect but also someone who stands in the way of Shinra's goals. He wouldn't likely harbor any personal feelings towards her, but rather see her as a professional obstacle to overcome. \n",
      "\n",
      "It's also worth noting that, while he is a loyal member of the Turks, he does exhibit a sense of honor and professionalism. So, he might be capable of recognizing and even appreciating Tifa's strength and fighting spirit, even if it goes against Shinra's interests.\n",
      "\n",
      "Ultimately, Rude's opinion of Tifa is left open to interpretation, adding to the mystery and intrigue surrounding his character. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What does he think about Tifa?\"\n",
    "response = gemini.run(prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see assistant role and message object were automatically transformed for Gemini API in the prompt field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[parts {\n",
       "   text: \"Do you know Rude in Final Fantasy VII?\"\n",
       " }\n",
       " role: \"user\",\n",
       " parts {\n",
       "   text: \"Yes, Rude is a character in the video game *Final Fantasy VII*. He is a member of the Turks, a covert group working for the Shinra Electric Power Company. Distinguished by his bald head, sunglasses, and silent demeanor, Rude is known for being a skilled fighter and loyal teammate. Throughout the game, players encounter Rude multiple times in various battles and story events, where he often acts alongside his partner Reno. Despite working for Shinra, Rude, along with other members of the Turks, is portrayed with a level of depth that reveals his own sense of honor and camaraderie.\"\n",
       " }\n",
       " role: \"model\",\n",
       " parts {\n",
       "   text: \"What does he think about Tifa?\"\n",
       " }\n",
       " role: \"user\"]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude can follow as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, I see where you're going with this. I apologize for missing that important detail in my previous response. You're absolutely right to bring this up, as there is indeed a subtle subplot involving Rude's feelings for Tifa in the game. Let me clarify:\n",
      "\n",
      "1. It's hinted in the game that Rude has a crush on Tifa.\n",
      "\n",
      "2. This is mostly revealed through interactions with his fellow Turks, particularly Reno.\n",
      "\n",
      "3. In one scene, Reno teases Rude about his crush on Tifa, showing that at least some of the Turks are aware of Rude's feelings.\n",
      "\n",
      "4. Rude is shown to be somewhat embarrassed about these feelings, which adds an interesting layer to his character.\n",
      "\n",
      "5. This crush is never explicitly addressed or acted upon in the main storyline, remaining a background detail that adds depth to Rude's character.\n",
      "\n",
      "So yes, some of the Turks (at least Reno) do know about Rude's feelings for Tifa. This creates an interesting dynamic, as Rude has to balance his professional duties with his personal feelings. Thank you for bringing this up - it's an important aspect of Rude's character that I should have mentioned earlier.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Does Turks members know his feeling?\"\n",
    "\n",
    "response = claude.run(prompt)\n",
    "\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to specify system instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langrila's module accepts system instruction as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For OpenAI Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"You must answer any question only with Yes or No.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_openai = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"API_KEY\",\n",
    "    model_name=\"gpt-4o-2024-05-13\",\n",
    "    api_type=\"openai\",\n",
    "    system_instruction=system_instruction,\n",
    "    conversation_memory=InMemoryConversationMemory(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Please tell me about how to sleep well.\"\n",
    "response = chat_openai.run(prompt=prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System prompt is not stored into conversation memory but it exists in prompt attribute in response object. It's bacause we can make system prompt replaceable flexibly. System prompt is inserted as a first message just before API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': {'role': 'assistant', 'content': [{'text': 'No.'}], 'name': None},\n",
       " 'usage': {'model_name': 'gpt-4o-2024-05-13',\n",
       "  'prompt_tokens': 34,\n",
       "  'completion_tokens': 2},\n",
       " 'prompt': [{'role': 'system',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'You must answer any question only with Yes or No.'}],\n",
       "   'name': 'System'},\n",
       "  {'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Please tell me about how to sleep well.'}],\n",
       "   'name': 'User'}]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see system prompt in the prompt attribute in the response\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': [{'text': 'Please tell me about how to sleep well.'}],\n",
       "  'name': None},\n",
       " {'role': 'assistant', 'content': [{'text': 'No.'}], 'name': None}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# System prompt is not shown in the conversation memory\n",
    "chat_openai.conversation_memory.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini and Claude also accept system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = GeminiFunctionalChat(\n",
    "    api_key_env_name=\"GEMINI_API_KEY\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_instruction=system_instruction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Please tell me about how to sleep well.\"\n",
    "response = gemini.run(prompt=prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = ClaudeFunctionalChat(\n",
    "    # For Anthropic\n",
    "    model_name=\"claude-3-5-sonnet-20240620\",\n",
    "    api_key_env_name=\"ANTHROPIC_API_KEY\",\n",
    "    system_instruction=system_instruction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Please tell me about how to sleep well.\"\n",
    "response = claude.run(prompt=prompt)\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For OpenAI Chat Completion, # of tokens is calculated before API call, and module truncates prompt automatically to make sure # of tokens meets token limitation. In this section, we simulate this truncation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_openai = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"API_KEY\",\n",
    "    model_name=\"gpt-4o-2024-05-13\",\n",
    "    api_type=\"openai\",\n",
    "    context_length=300,  # You can control the number of tokens in the prompt\n",
    "    conversation_memory=InMemoryConversationMemory(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input message is truncated because total length of messages exceeds context length.\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"What is the pheasant?\",\n",
    "    \"Please tell me about a bird called Kiji in Japan.\",\n",
    "    \"What does Kiji do in the tale of the Momotaro\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = chat_openai.run(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old conversation was truncated as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=299, completion_tokens=459, total_tokens=758)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE : Usage after truncation might slightly be different from the specified context_length\n",
    "response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant',\n",
       "  'name': 'Assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': ' Green Pheasants typically inhabit woodlands, agricultural fields, and grasslands. They are commonly found near human settlements and farmland, as they can benefit from the available food sources.\\n- **Diet**: They are omnivorous, feeding on a variety of seeds, leaves, insects, and small animals.\\n- **Behavior**: These birds are ground-dwellers although they can fly short distances if necessary. They are known for their distinctive calls, especially during the mating season.\\n\\n### Cultural Significance:\\n- **Symbolism**: In Japanese culture, the Green Pheasant is a symbol of beauty and strength. It appears in various forms of traditional art and literature.\\n- **National Bird**: The bird was designated the national bird of Japan in 1947.\\n- **Folklore**: The Japanese Green Pheasant also appears in folklore and mythology. In some tales, they are seen as messengers of the gods or protectors against evil spirits.\\n\\n### Conservation:\\nWhile not currently endangered, the habitat and population of the Japanese Green Pheasant are monitored to ensure they remain healthy and stable, given their cultural and ecological importance.\\n\\nIn summary, the Kiji or Japanese Green Pheasant is a distinct and culturally significant bird in Japan, known for its beautiful appearance and deep-rooted presence in Japanese folklore and tradition.'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'What does Kiji do in the tale of the Momotaro'}],\n",
       "  'name': 'User'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But truncation does not affect conversation memory itself. You can see full conversation history in the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': [{'text': 'What is the pheasant?'}],\n",
       "  'name': None},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'text': 'The pheasant is a type of bird that belongs to the family Phasianidae, which also includes partridges, quails, and peafowls. Pheasants are known for their vibrant plumage, especially the males, which often have bright colors and intricate patterns to attract mates. One of the most well-known species is the Common Pheasant (Phasianus colchicus), which is native to Asia but has been introduced to many other parts of the world, including North America and Europe, primarily for hunting and ornamental purposes.\\n\\nPheasants are typically ground-dwelling birds, although they can fly short distances. They are omnivorous, feeding on a variety of foods such as seeds, insects, and small animals. Their habitats vary widely, from grasslands to forest edges, and they often prefer areas with dense underbrush for cover.\\n\\nThe males are usually larger and more colorful than the females, which are more subdued in coloration to provide camouflage while nesting. Pheasants are also known for their loud calls and striking courtship displays.\\n\\nIn many cultures, pheasants are associated with hunting and are considered a symbol of the countryside. They have also found a place in culinary traditions, particularly in game dishes.'}],\n",
       "  'name': None},\n",
       " {'role': 'user',\n",
       "  'content': [{'text': 'Please tell me about a bird called Kiji in Japan.'}],\n",
       "  'name': None},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'text': 'The bird known as \"Kiji\" in Japan refers to the Japanese Green Pheasant (Phasianus versicolor). It is a species of pheasant native to the archipelago of Japan and is considered the national bird of the country. The Japanese Green Pheasant is renowned for its vibrant and striking plumage.\\n\\n### Appearance:\\n- **Males**: The males are particularly striking, featuring a beautiful iridescent green plumage on their body, with purple and blue shades on the neck and breast. They also have bright red facial wattles and a long, elegant tail.\\n- **Females**: The females have more subdued coloring, generally brown and mottled, which helps them blend into their surroundings when nesting.\\n\\n### Behavior and Habitat:\\n- **Habitat**: Japanese Green Pheasants typically inhabit woodlands, agricultural fields, and grasslands. They are commonly found near human settlements and farmland, as they can benefit from the available food sources.\\n- **Diet**: They are omnivorous, feeding on a variety of seeds, leaves, insects, and small animals.\\n- **Behavior**: These birds are ground-dwellers although they can fly short distances if necessary. They are known for their distinctive calls, especially during the mating season.\\n\\n### Cultural Significance:\\n- **Symbolism**: In Japanese culture, the Green Pheasant is a symbol of beauty and strength. It appears in various forms of traditional art and literature.\\n- **National Bird**: The bird was designated the national bird of Japan in 1947.\\n- **Folklore**: The Japanese Green Pheasant also appears in folklore and mythology. In some tales, they are seen as messengers of the gods or protectors against evil spirits.\\n\\n### Conservation:\\nWhile not currently endangered, the habitat and population of the Japanese Green Pheasant are monitored to ensure they remain healthy and stable, given their cultural and ecological importance.\\n\\nIn summary, the Kiji or Japanese Green Pheasant is a distinct and culturally significant bird in Japan, known for its beautiful appearance and deep-rooted presence in Japanese folklore and tradition.'}],\n",
       "  'name': None},\n",
       " {'role': 'user',\n",
       "  'content': [{'text': 'What does Kiji do in the tale of the Momotaro'}],\n",
       "  'name': None},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'text': 'In the Japanese folktale \"Momotaro,\" Kiji, which translates to pheasant, is one of Momotaro\\'s loyal animal companions. The tale goes as follows:\\n\\n### The Story of Momotaro:\\nMomotaro, meaning \"Peach Boy,\" is a child born from a giant peach. He is discovered and adopted by an elderly couple who find the peach floating down the river. When Momotaro grows up, he embarks on a journey to defeat a band of oni (demons or ogres) that have been terrorizing their village.\\n\\n### Role of Kiji in the Tale:\\n- **First Encounter**: During his journey, Momotaro meets several animals who become his companions, starting with a talking dog, then a monkey, and finally, the pheasant (Kiji).\\n- **Joining the Team**: Momotaro shares his kibi dango (millet dumplings) with each animal, gaining their loyalty. The pheasant agrees to join Momotaro in exchange for a portion of these dumplings.\\n- **Contributions to the Mission**: \\n  - **Scouting**: Kiji plays a crucial role in the mission due to its ability to fly. The pheasant scouts ahead, gathering information and relaying it back to Momotaro and the other animals.\\n  - **Combat**: In the battle against the oni, Kiji uses its ability to fly to swoop down and attack the demons, distracting and harassing them, thus aiding Momotaro and the other animals in their fight.\\n  \\n### Significance:\\n- **Symbol of Strategy and Communication**: Kijiâ€™s actions often symbolize strategic thinking and the importance of communication. By scouting ahead and relaying critical information, the pheasant ensures that the team can plan their attack effectively.\\n- **Teamwork**: The story highlights the importance of teamwork and how each memberâ€™s unique abilities contribute to the success of their mission.\\n\\nIn the end, with the help of his animal companions, including the pheasant, Momotaro successfully defeats the oni, retrieves their treasures, and returns home as a hero. The tale of Momotaro and his companions, including Kiji, underscores themes of bravery, loyalty, and the power of cooperation.'}],\n",
       "  'name': None}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_openai.conversation_memory.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If prompts contain some images and # of tokens exceeds limitation, image might be truncated entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage gathering across multiple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage object allows you to sum multiple usages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=300, completion_tokens=150, total_tokens=450)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage1 = Usage(model_name=\"gpt-4o-2024-05-13\", prompt_tokens=100, completion_tokens=50)\n",
    "\n",
    "usage2 = Usage(model_name=\"gpt-4o-2024-05-13\", prompt_tokens=200, completion_tokens=100)\n",
    "\n",
    "usage1 + usage2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage don't have capability to sum usages from different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error!\n"
     ]
    }
   ],
   "source": [
    "usage3 = Usage(model_name=\"gpt-4o-mini-2024-07-18\", prompt_tokens=300, completion_tokens=150)\n",
    "\n",
    "try:\n",
    "    usage1 + usage3  # Error\n",
    "except:\n",
    "    print(\"Error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But usage with empty model_name is added to any other usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=200, completion_tokens=100, total_tokens=300)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage4 = Usage(prompt_tokens=100, completion_tokens=50)\n",
    "\n",
    "usage1 + usage4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, it's not possible to add usage to usage of empty model_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    usage4 + usage1\n",
    "except:\n",
    "    print(\"Error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function, we sometimes want to sum up total #of tokens over each models. In langrila, shared token counter is available to integrate total usage from multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langrila import TokenCounter\n",
    "\n",
    "shared_memory = InMemoryConversationMemory()\n",
    "\n",
    "shared_token_counter = TokenCounter()\n",
    "\n",
    "gemini = GeminiFunctionalChat(\n",
    "    api_key_env_name=\"GEMINI_API_KEY\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    conversation_memory=shared_memory,\n",
    "    token_counter=shared_token_counter,\n",
    ")\n",
    "\n",
    "chat_openai = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"API_KEY\",\n",
    "    model_name=\"gpt-4o-2024-05-13\",\n",
    "    api_type=\"openai\",\n",
    "    conversation_memory=shared_memory,\n",
    "    token_counter=shared_token_counter,\n",
    ")\n",
    "\n",
    "claude = ClaudeFunctionalChat(\n",
    "    model_name=\"claude-3-5-sonnet-20240620\",\n",
    "    api_key_env_name=\"ANTHROPIC_API_KEY\",\n",
    "    conversation_memory=shared_memory,\n",
    "    token_counter=shared_token_counter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"What is the pheasant?\",\n",
    "    \"Please tell me about a bird called Kiji in Japan.\",\n",
    "    \"What does Kiji do in the tale of the Momotaro\",\n",
    "]\n",
    "\n",
    "clients = [gemini, chat_openai, claude]\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    client = clients[i]\n",
    "    response = client.run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-1.5-flash': Usage(prompt_tokens=6, completion_tokens=424, total_tokens=430), 'gpt-4o-2024-05-13': Usage(prompt_tokens=475, completion_tokens=582, total_tokens=1057), 'claude-3-5-sonnet-20240620': Usage(prompt_tokens=1198, completion_tokens=407, total_tokens=1605)}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_token_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manage a typical prompt as a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# INSTRUCTION\n",
      "{instruction}\n",
      "\n",
      "# TEXT\n",
      "{text}\n"
     ]
    }
   ],
   "source": [
    "template = PromptTemplate.from_text_file(\"../data/sample_prompt_template.txt\")\n",
    "print(template.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(args={'instruction': 'Hello', 'text': 'world!'}, template='# INSTRUCTION\\n{instruction}\\n\\n# TEXT\\n{text}')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.set_args(instruction=\"Hello\", text=\"world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# INSTRUCTION\n",
      "Hello\n",
      "\n",
      "# TEXT\n",
      "world!\n"
     ]
    }
   ],
   "source": [
    "print(template.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass template string to PromptTemplate directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(args={}, template='# INSTRUCTION\\n{instruction}\\n\\n# TEXT\\n{text}')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PromptTemplate(template=\"# INSTRUCTION\\n{instruction}\\n\\n# TEXT\\n{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
