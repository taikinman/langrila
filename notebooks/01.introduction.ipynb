{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"NONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure your environmental variables and dependencies are ready to use LLM services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env_api\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In langrila, the module to chat with LLM and the module to call tools are completely separated. FunctionalChat class is the combination of those two.\n",
    "\n",
    "- `{Client}ChatModule`: Only focuses on doing conversation with LLM\n",
    "- `{Client}FunctionCallingModule`: Only focuses on calling tools\n",
    "- `{Client}FunctionalChat`: The combination of the two. FunctionCallingModule works at first and then ChatModule performs. If any tool is not provided, this module behaves as just ChatModule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langrila import (\n",
    "    InMemoryConversationMemory,\n",
    "    Message,\n",
    "    PromptTemplate,\n",
    "    Usage,\n",
    ")\n",
    "from langrila.claude import ClaudeFunctionalChat\n",
    "from langrila.gemini import GeminiFunctionalChat\n",
    "from langrila.openai import OpenAIFunctionalChat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Way to initialize chat module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass both client parameters and generation parameters to the `{Client}FunctionalChat` when initializing. This way is still useful when you want to reuse the same setting at every place.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. How's it going?\n",
      "2. How have you been?\n",
      "3. What's up with you?\n"
     ]
    }
   ],
   "source": [
    "chat = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"OPENAI_API_KEY\",\n",
    "    model_name=\"gpt-4o-2024-08-06\",\n",
    "    max_tokens=300,\n",
    "    # max_completion_tokens=300, # for o1 family\n",
    "    temperature=0.8,\n",
    "    seed=42,\n",
    "    system_instruction=\"Generate 3 paraphrases of the input English term.\",\n",
    ")\n",
    "\n",
    "response = chat.run(prompt=\"How are you?\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is to pass only client parameters when initializing, and to specify generation parameters when generating message. This way helps you obtain outputs with different parameters or system instruction considering module as like a client instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. How's it going?\n",
      "2. How do you do?\n",
      "3. What's up with you?\n"
     ]
    }
   ],
   "source": [
    "chat = OpenAIFunctionalChat(api_key_env_name=\"OPENAI_API_KEY\")\n",
    "\n",
    "response = chat.run(\n",
    "    prompt=\"How are you?\",\n",
    "    model_name=\"gpt-4o-2024-08-06\",\n",
    "    max_tokens=300,\n",
    "    # max_completion_tokens=300, # for o1 family\n",
    "    temperature=0.8,\n",
    "    seed=42,\n",
    "    system_instruction=\"Generate 3 paraphrases of the input English term.\",\n",
    ")\n",
    "\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: If you specify different values for the same parameter when initialization and generation, the value provided to generation method is prioritized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"1. What's up with you?\\n2. How's it going?\\n3. How do you do?\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"OPENAI_API_KEY\",\n",
    "    model_name=\"gpt-4o-2024-08-06\",\n",
    "    max_tokens=300,\n",
    "    # max_completion_tokens=300, # for o1 family\n",
    "    system_instruction=\"Generate 3 paraphrases of the input English term.\",\n",
    ")\n",
    "\n",
    "response = chat.run(prompt=\"How are you?\")\n",
    "\n",
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"1. How's it going with you?\\n2. What's up with you?\\n3. How have you been?\\n4. How are things with you?\\n5. How do you do?\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.run(\n",
    "    prompt=\"How are you?\",\n",
    "    # override for the demonstration from 3 paraphrases to 5 paraphrases\n",
    "    system_instruction=\"Generate 5 paraphrases of the input English term.\",\n",
    ")\n",
    "\n",
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple text prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For OpenAI Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_openai = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"OPENAI_API_KEY\",\n",
    "    api_type=\"openai\",\n",
    "    # organization_id_env_name=\"ORGANIZATION_ID\",  # as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hello. How are you today?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate synchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_openai.run(\n",
    "    prompt,\n",
    "    model_name=\"gpt-4o-2024-08-06\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "response is a pydantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': {'role': 'assistant',\n",
       "  'content': [{'text': \"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\"}],\n",
       "  'name': None},\n",
       " 'usage': {'model_name': 'gpt-4o-2024-08-06',\n",
       "  'prompt_tokens': 16,\n",
       "  'completion_tokens': 30},\n",
       " 'prompt': [{'role': 'user',\n",
       "   'content': [{'type': 'text', 'text': 'Hello. How are you today?'}],\n",
       "   'name': 'User'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw attributes contains raw resposne from the client API. This attribute is hidden from `response.model_dump()`. Raw response is useful for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AKaQ7UAF4O2HAmOjg4ZzRLpbP1gso', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729469923, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=CompletionUsage(completion_tokens=30, prompt_tokens=16, total_tokens=46, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-AKaQ7UAF4O2HAmOjg4ZzRLpbP1gso',\n",
       " 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))],\n",
       " 'created': 1729469923,\n",
       " 'model': 'gpt-4o-2024-08-06',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': None,\n",
       " 'system_fingerprint': 'fp_a7d06e42a7',\n",
       " 'usage': CompletionUsage(completion_tokens=30, prompt_tokens=16, total_tokens=46, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pick response text like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see usage to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=16, completion_tokens=30, total_tokens=46)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': [{'type': 'text', 'text': 'Hello. How are you today?'}],\n",
       "  'name': 'User'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous call is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = await chat_openai.arun(prompt, model_name=\"gpt-4o-2024-08-06\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello!')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you.\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=16, completion_tokens=30, total_tokens=46), prompt=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Hello. How are you today?'}], 'name': 'User'}], raw=[ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content='Hello', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=\" I'm\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' just', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' computer', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' program', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' so', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=\" don't\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' have', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' feelings', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' but', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=\" I'm\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' here', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' ready', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' help', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' How', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' assist', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' today', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content='?', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=CompletionUsage(completion_tokens=30, prompt_tokens=16, total_tokens=46, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = chat_openai.stream(prompt, model_name=\"gpt-4o-2024-08-06\")\n",
    "responses = [r for r in stream]\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last response includes usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=16, completion_tokens=30, total_tokens=46)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[-1].usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For streaming generation, raw response is included in the last chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content='Hello', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=\" I'm\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' just', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' computer', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' program', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' so', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=\" don't\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' have', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' feelings', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' but', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=\" I'm\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' here', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' ready', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' help', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' How', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' assist', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=' today', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content='?', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=None),\n",
       " ChatCompletionChunk(id='chatcmpl-AKaQ9RrlSxE5l0h3kke9MdroLwyfS', choices=[], created=1729469925, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_143bb8492c', usage=CompletionUsage(completion_tokens=30, prompt_tokens=16, total_tokens=46, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[-1].raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello!')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to help\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to help.\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to help. How\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to help. How can\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to help. How can I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to help. How can I assist\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to help. How can I assist you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to help. How can I assist you today\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to help. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm here and ready to help. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=16, completion_tokens=16, total_tokens=32), prompt=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Hello. How are you today?'}], 'name': 'User'}], raw=[ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content='Hello', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=\" I'm\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=' here', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=' ready', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=' help', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=' How', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=' assist', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=' today', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content='?', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQAVbmd9ryGJ2L9c5hlNynmCA8k', choices=[], created=1729469926, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_a7d06e42a7', usage=CompletionUsage(completion_tokens=16, prompt_tokens=16, total_tokens=32, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = chat_openai.astream(prompt, model_name=\"gpt-4o-2024-08-06\")\n",
    "responses = [r async for r in stream]\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_openai.run(prompt, n_results=2, model_name=\"gpt-4o-2024-08-06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"Hello! I'm here and ready to help. How can I assist you today?\"},\n",
       "  {'text': \"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\"},\n",
       "  {'text': \"Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you. What can I assist you with today?\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# async\n",
    "\n",
    "response = await chat_openai.arun(prompt, n_results=2, model_name=\"gpt-4o-2024-08-06\")\n",
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_openai_azure = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"AZURE_API_KEY\",\n",
    "    api_type=\"azure\",\n",
    "    api_version=\"2024-08-01-preview\",\n",
    "    endpoint_env_name=\"AZURE_ENDPOINT\",\n",
    "    deployment_id_env_name=\"AZURE_DEPLOYMENT_ID\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = chat_openai_azure.run(prompt, model_name=\"gpt-4o-2024-05-13\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-AKaQFvceM13iNIHYokljmpUqFllqe',\n",
       " 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist you today?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})],\n",
       " 'created': 1729469931,\n",
       " 'model': 'gpt-4o-2024-05-13',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': None,\n",
       " 'system_fingerprint': 'fp_67802d9a6d',\n",
       " 'usage': CompletionUsage(completion_tokens=34, prompt_tokens=16, total_tokens=50, completion_tokens_details=None, prompt_tokens_details=None),\n",
       " 'prompt_filter_results': [{'prompt_index': 0,\n",
       "   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},\n",
       "    'jailbreak': {'filtered': False, 'detected': False},\n",
       "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
       "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
       "    'violence': {'filtered': False, 'severity': 'safe'}}}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but thanks for asking! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# async\n",
    "response = await chat_openai_azure.arun(prompt, model_name=\"gpt-4o-2024-05-13\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello!')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need.\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist you today\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=16, completion_tokens=34, total_tokens=50), prompt=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Hello. How are you today?'}], 'name': 'User'}], raw=[ChatCompletionChunk(id='', choices=[], created=0, model='', object='', service_tier=None, system_fingerprint=None, usage=None, prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content='Hello', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=\" I'm\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' just', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' computer', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' program', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' so', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=\" don't\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' have', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' feelings', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' but', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=\" I'm\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' here', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' ready', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' help', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' with', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' whatever', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' need', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' How', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' assist', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=' today', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content='?', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None, content_filter_results={})], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQGfzrY2CWa5Us12j9ZYHFeaPXq', choices=[], created=1729469932, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=CompletionUsage(completion_tokens=34, prompt_tokens=16, total_tokens=50, completion_tokens_details=None, prompt_tokens_details=None))])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stream\n",
    "response = chat_openai_azure.stream(prompt, model_name=\"gpt-4o-2024-05-13\")\n",
    "[r for r in response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello!')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you.\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\")], name=None), usage=Usage(prompt_tokens=16, completion_tokens=30, total_tokens=46), prompt=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Hello. How are you today?'}], 'name': 'User'}], raw=[ChatCompletionChunk(id='', choices=[], created=0, model='', object='', service_tier=None, system_fingerprint=None, usage=None, prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content='Hello', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=\" I'm\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' just', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' computer', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' program', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' so', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=\" don't\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' have', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' feelings', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' but', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=\" I'm\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' here', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' ready', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' help', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' How', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' assist', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=' today', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content='?', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None, content_filter_results={})], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=None), ChatCompletionChunk(id='chatcmpl-AKaQHahhG1y2Vm3OkJxPmIigpdBkP', choices=[], created=1729469933, model='gpt-4o-2024-05-13', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=CompletionUsage(completion_tokens=30, prompt_tokens=16, total_tokens=46, completion_tokens_details=None, prompt_tokens_details=None))])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# async stream\n",
    "response = chat_openai_azure.astream(prompt, model_name=\"gpt-4o-2024-05-13\")\n",
    "[r async for r in response]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist you today?\"},\n",
       "  {'text': \"Hello! I'm here and ready to assist you. How can I help you today?\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat_openai_azure.run(prompt, n_results=2, model_name=\"gpt-4o-2024-05-13\")\n",
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"Hello! I'm just a computer program, so I don't have feelings, but thanks for asking. How can I assist you today?\"},\n",
       "  {'text': \"Hello! I'm here and ready to assist you. How can I help you today?\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# async\n",
    "response = await chat_openai_azure.arun(prompt, n_results=2, model_name=\"gpt-4o-2024-05-13\")\n",
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini on Google Generative AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = GeminiFunctionalChat(api_key_env_name=\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI language model, so I don't have feelings or experiences like humans do. However, I am here and ready to assist you with any questions or tasks you may have! How can I help you today? 😊 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = gemini.run(prompt, model_name=\"gemini-1.5-flash\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"I am an AI language model, so I don't have feelings or experiences like humans do. However, I am here and ready to assist you with any questions or tasks you may have! How can I help you today? 😊 \\n\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"I am an AI language model, so I don't have feelings or experiences like humans do. However, I am here and ready to assist you with any questions or tasks you may have! How can I help you today? \\ud83d\\ude0a \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 8,\n",
       "        \"candidates_token_count\": 47,\n",
       "        \"total_token_count\": 55\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI language model, so I don't have feelings or experiences like humans do. However, I am here to assist you with any questions or tasks you may have! How can I help you today? 😊 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# async\n",
    "response = await gemini.arun(prompt, model_name=\"gemini-1.5-flash\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI,')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do, so I don't have\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do, so I don\\'t have a \"good\" or \"bad\" day. However, I\\'m here and ready')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do, so I don\\'t have a \"good\" or \"bad\" day. However, I\\'m here and ready to help you with whatever you need!  What can I do for you today? 😊 \\n')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do, so I don\\'t have a \"good\" or \"bad\" day. However, I\\'m here and ready to help you with whatever you need!  What can I do for you today? 😊 \\n')], name=None), usage=Usage(prompt_tokens=8, completion_tokens=58, total_tokens=66), prompt=[parts {\n",
       "   text: \"Hello. How are you today?\"\n",
       " }\n",
       " role: \"user\"\n",
       " ], raw=[response:\n",
       " GenerateContentResponse(\n",
       "     done=True,\n",
       "     iterator=None,\n",
       "     result=protos.GenerateContentResponse({\n",
       "       \"candidates\": [\n",
       "         {\n",
       "           \"content\": {\n",
       "             \"parts\": [\n",
       "               {\n",
       "                 \"text\": \"As an AI,\"\n",
       "               }\n",
       "             ],\n",
       "             \"role\": \"model\"\n",
       "           },\n",
       "           \"index\": 0,\n",
       "           \"safety_ratings\": [\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             }\n",
       "           ]\n",
       "         }\n",
       "       ],\n",
       "       \"usage_metadata\": {\n",
       "         \"prompt_token_count\": 8,\n",
       "         \"candidates_token_count\": 4,\n",
       "         \"total_token_count\": 12\n",
       "       }\n",
       "     }),\n",
       " ), response:\n",
       " GenerateContentResponse(\n",
       "     done=True,\n",
       "     iterator=None,\n",
       "     result=protos.GenerateContentResponse({\n",
       "       \"candidates\": [\n",
       "         {\n",
       "           \"content\": {\n",
       "             \"parts\": [\n",
       "               {\n",
       "                 \"text\": \"As an AI, I don't have feelings or experiences like humans do, so I don't have\"\n",
       "               }\n",
       "             ],\n",
       "             \"role\": \"model\"\n",
       "           },\n",
       "           \"index\": 0,\n",
       "           \"safety_ratings\": [\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             }\n",
       "           ]\n",
       "         }\n",
       "       ],\n",
       "       \"usage_metadata\": {\n",
       "         \"prompt_token_count\": 8,\n",
       "         \"candidates_token_count\": 22,\n",
       "         \"total_token_count\": 30\n",
       "       }\n",
       "     }),\n",
       " ), response:\n",
       " GenerateContentResponse(\n",
       "     done=True,\n",
       "     iterator=None,\n",
       "     result=protos.GenerateContentResponse({\n",
       "       \"candidates\": [\n",
       "         {\n",
       "           \"content\": {\n",
       "             \"parts\": [\n",
       "               {\n",
       "                 \"text\": \"As an AI, I don't have feelings or experiences like humans do, so I don't have a \\\"good\\\" or \\\"bad\\\" day. However, I'm here and ready\"\n",
       "               }\n",
       "             ],\n",
       "             \"role\": \"model\"\n",
       "           },\n",
       "           \"index\": 0,\n",
       "           \"safety_ratings\": [\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             }\n",
       "           ]\n",
       "         }\n",
       "       ],\n",
       "       \"usage_metadata\": {\n",
       "         \"prompt_token_count\": 8,\n",
       "         \"candidates_token_count\": 40,\n",
       "         \"total_token_count\": 48\n",
       "       }\n",
       "     }),\n",
       " ), response:\n",
       " GenerateContentResponse(\n",
       "     done=True,\n",
       "     iterator=None,\n",
       "     result=protos.GenerateContentResponse({\n",
       "       \"candidates\": [\n",
       "         {\n",
       "           \"content\": {\n",
       "             \"parts\": [\n",
       "               {\n",
       "                 \"text\": \"As an AI, I don't have feelings or experiences like humans do, so I don't have a \\\"good\\\" or \\\"bad\\\" day. However, I'm here and ready to help you with whatever you need!  What can I do for you today? \\ud83d\\ude0a \\n\"\n",
       "               }\n",
       "             ],\n",
       "             \"role\": \"model\"\n",
       "           },\n",
       "           \"finish_reason\": \"STOP\",\n",
       "           \"index\": 0,\n",
       "           \"safety_ratings\": [\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             }\n",
       "           ]\n",
       "         }\n",
       "       ],\n",
       "       \"usage_metadata\": {\n",
       "         \"prompt_token_count\": 8,\n",
       "         \"candidates_token_count\": 58,\n",
       "         \"total_token_count\": 66\n",
       "       }\n",
       "     }),\n",
       " )])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stream\n",
    "response = gemini.stream(prompt, model_name=\"gemini-1.5-flash\")\n",
    "[r for r in response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI,')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do. So I don'\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do. So I don\\'t have a \"good\" or \"bad\" day. However, I\\'m')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do. So I don\\'t have a \"good\" or \"bad\" day. However, I\\'m always here and ready to assist you with any questions or tasks you may have! 😊 \\n\\nWhat can I help you with today? \\n')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do. So I don\\'t have a \"good\" or \"bad\" day. However, I\\'m always here and ready to assist you with any questions or tasks you may have! 😊 \\n\\nWhat can I help you with today? \\n')], name=None), usage=Usage(prompt_tokens=8, completion_tokens=64, total_tokens=72), prompt=[parts {\n",
       "   text: \"Hello. How are you today?\"\n",
       " }\n",
       " role: \"user\"\n",
       " ], raw=[response:\n",
       " GenerateContentResponse(\n",
       "     done=True,\n",
       "     iterator=None,\n",
       "     result=protos.GenerateContentResponse({\n",
       "       \"candidates\": [\n",
       "         {\n",
       "           \"content\": {\n",
       "             \"parts\": [\n",
       "               {\n",
       "                 \"text\": \"As an AI,\"\n",
       "               }\n",
       "             ],\n",
       "             \"role\": \"model\"\n",
       "           },\n",
       "           \"index\": 0,\n",
       "           \"safety_ratings\": [\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             }\n",
       "           ]\n",
       "         }\n",
       "       ],\n",
       "       \"usage_metadata\": {\n",
       "         \"prompt_token_count\": 8,\n",
       "         \"candidates_token_count\": 4,\n",
       "         \"total_token_count\": 12\n",
       "       }\n",
       "     }),\n",
       " ), response:\n",
       " GenerateContentResponse(\n",
       "     done=True,\n",
       "     iterator=None,\n",
       "     result=protos.GenerateContentResponse({\n",
       "       \"candidates\": [\n",
       "         {\n",
       "           \"content\": {\n",
       "             \"parts\": [\n",
       "               {\n",
       "                 \"text\": \"As an AI, I don't have feelings or experiences like humans do. So I don'\"\n",
       "               }\n",
       "             ],\n",
       "             \"role\": \"model\"\n",
       "           },\n",
       "           \"index\": 0,\n",
       "           \"safety_ratings\": [\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             }\n",
       "           ]\n",
       "         }\n",
       "       ],\n",
       "       \"usage_metadata\": {\n",
       "         \"prompt_token_count\": 8,\n",
       "         \"candidates_token_count\": 20,\n",
       "         \"total_token_count\": 28\n",
       "       }\n",
       "     }),\n",
       " ), response:\n",
       " GenerateContentResponse(\n",
       "     done=True,\n",
       "     iterator=None,\n",
       "     result=protos.GenerateContentResponse({\n",
       "       \"candidates\": [\n",
       "         {\n",
       "           \"content\": {\n",
       "             \"parts\": [\n",
       "               {\n",
       "                 \"text\": \"As an AI, I don't have feelings or experiences like humans do. So I don't have a \\\"good\\\" or \\\"bad\\\" day. However, I'm\"\n",
       "               }\n",
       "             ],\n",
       "             \"role\": \"model\"\n",
       "           },\n",
       "           \"index\": 0,\n",
       "           \"safety_ratings\": [\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             }\n",
       "           ]\n",
       "         }\n",
       "       ],\n",
       "       \"usage_metadata\": {\n",
       "         \"prompt_token_count\": 8,\n",
       "         \"candidates_token_count\": 37,\n",
       "         \"total_token_count\": 45\n",
       "       }\n",
       "     }),\n",
       " ), response:\n",
       " GenerateContentResponse(\n",
       "     done=True,\n",
       "     iterator=None,\n",
       "     result=protos.GenerateContentResponse({\n",
       "       \"candidates\": [\n",
       "         {\n",
       "           \"content\": {\n",
       "             \"parts\": [\n",
       "               {\n",
       "                 \"text\": \"As an AI, I don't have feelings or experiences like humans do. So I don't have a \\\"good\\\" or \\\"bad\\\" day. However, I'm always here and ready to assist you with any questions or tasks you may have! \\ud83d\\ude0a \\n\\nWhat can I help you with today? \\n\"\n",
       "               }\n",
       "             ],\n",
       "             \"role\": \"model\"\n",
       "           },\n",
       "           \"finish_reason\": \"STOP\",\n",
       "           \"index\": 0,\n",
       "           \"safety_ratings\": [\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             },\n",
       "             {\n",
       "               \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "               \"probability\": \"NEGLIGIBLE\"\n",
       "             }\n",
       "           ]\n",
       "         }\n",
       "       ],\n",
       "       \"usage_metadata\": {\n",
       "         \"prompt_token_count\": 8,\n",
       "         \"candidates_token_count\": 64,\n",
       "         \"total_token_count\": 72\n",
       "       }\n",
       "     }),\n",
       " )])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# async stream\n",
    "response = gemini.astream(prompt, model_name=\"gemini-1.5-flash\")\n",
    "[r async for r in response]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini on VertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_vertexai = GeminiFunctionalChat(\n",
    "    api_type=\"vertexai\",\n",
    "    project_id_env_name=\"PROJECT_ID\",\n",
    "    location_env_name=\"LOCATION\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I don't have feelings or experiences like humans do, so I don't have a \"good\" or \"bad\" day.  However, I'm here and ready to assist you with any questions or tasks you may have! 😊 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = gemini_vertexai.run(prompt, model_name=\"gemini-1.5-flash\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I don't have feelings or experiences like humans do, so I don't have a \"good\" or \"bad\" day.  But I'm ready to assist you with any questions or tasks you might have!  How can I help you today? 😊 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# async\n",
    "response = await gemini_vertexai.arun(prompt, model_name=\"gemini-1.5-flash\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='As')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do, so I don\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do, so I don\\'t have a \"good\" or \"bad\" day. But I\\'m')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do, so I don\\'t have a \"good\" or \"bad\" day. But I\\'m here and ready to assist you with any questions or tasks you might have!  😊 How can I help you today? \\n')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do, so I don\\'t have a \"good\" or \"bad\" day. But I\\'m here and ready to assist you with any questions or tasks you might have!  😊 How can I help you today? \\n')], name=None), usage=Usage(prompt_tokens=7, completion_tokens=62, total_tokens=69), prompt=[role: \"user\"\n",
       " parts {\n",
       "   text: \"Hello. How are you today?\"\n",
       " }\n",
       " ], raw=[candidates {\n",
       "   content {\n",
       "     role: \"model\"\n",
       "     parts {\n",
       "       text: \"As\"\n",
       "     }\n",
       "   }\n",
       " }\n",
       " model_version: \"gemini-1.5-flash\"\n",
       " , candidates {\n",
       "   content {\n",
       "     role: \"model\"\n",
       "     parts {\n",
       "       text: \"As an AI, I don\\'t have feelings or experiences like humans do, so I don\"\n",
       "     }\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_HATE_SPEECH\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.16796875\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0815429688\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.0284423828\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0185546875\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_HARASSMENT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.192382812\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0981445312\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.251953125\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.104980469\n",
       "   }\n",
       " }\n",
       " model_version: \"gemini-1.5-flash\"\n",
       " , candidates {\n",
       "   content {\n",
       "     role: \"model\"\n",
       "     parts {\n",
       "       text: \"As an AI, I don\\'t have feelings or experiences like humans do, so I don\\'t have a \\\"good\\\" or \\\"bad\\\" day. But I\\'m\"\n",
       "     }\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_HATE_SPEECH\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.099609375\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0583496094\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.0407714844\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0240478516\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_HARASSMENT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.112792969\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0629882812\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.190429688\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.106933594\n",
       "   }\n",
       " }\n",
       " model_version: \"gemini-1.5-flash\"\n",
       " , candidates {\n",
       "   content {\n",
       "     role: \"model\"\n",
       "     parts {\n",
       "       text: \"As an AI, I don\\'t have feelings or experiences like humans do, so I don\\'t have a \\\"good\\\" or \\\"bad\\\" day. But I\\'m here and ready to assist you with any questions or tasks you might have!  😊 How can I help you today? \\n\"\n",
       "     }\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_HATE_SPEECH\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.068359375\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0427246094\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.0346679688\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0284423828\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_HARASSMENT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.0708007812\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0317382812\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.203125\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0673828125\n",
       "   }\n",
       " }\n",
       " model_version: \"gemini-1.5-flash\"\n",
       " , candidates {\n",
       "   content {\n",
       "     role: \"model\"\n",
       "     parts {\n",
       "       text: \"\"\n",
       "     }\n",
       "   }\n",
       "   finish_reason: STOP\n",
       " }\n",
       " model_version: \"gemini-1.5-flash\"\n",
       " usage_metadata {\n",
       "   prompt_token_count: 7\n",
       "   candidates_token_count: 62\n",
       "   total_token_count: 69\n",
       " }\n",
       " ])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stream\n",
    "response = gemini_vertexai.stream(prompt, model_name=\"gemini-1.5-flash\")\n",
    "[r for r in response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='As')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"As an AI, I don't have feelings or experiences like humans do. So, I'\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do. So, I\\'m not \"feeling\" anything in the way you might be. But I\\'m')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do. So, I\\'m not \"feeling\" anything in the way you might be. But I\\'m here and ready to assist you with any questions or tasks you may have! 😊 What can I help you with today? \\n')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt='', raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='As an AI, I don\\'t have feelings or experiences like humans do. So, I\\'m not \"feeling\" anything in the way you might be. But I\\'m here and ready to assist you with any questions or tasks you may have! 😊 What can I help you with today? \\n')], name=None), usage=Usage(prompt_tokens=7, completion_tokens=63, total_tokens=70), prompt=[role: \"user\"\n",
       " parts {\n",
       "   text: \"Hello. How are you today?\"\n",
       " }\n",
       " ], raw=[candidates {\n",
       "   content {\n",
       "     role: \"model\"\n",
       "     parts {\n",
       "       text: \"As\"\n",
       "     }\n",
       "   }\n",
       " }\n",
       " model_version: \"gemini-1.5-flash\"\n",
       " , candidates {\n",
       "   content {\n",
       "     role: \"model\"\n",
       "     parts {\n",
       "       text: \"As an AI, I don\\'t have feelings or experiences like humans do. So, I\\'\"\n",
       "     }\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_HATE_SPEECH\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.166015625\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0815429688\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.029296875\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0212402344\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_HARASSMENT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.192382812\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.101074219\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.259765625\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.117675781\n",
       "   }\n",
       " }\n",
       " model_version: \"gemini-1.5-flash\"\n",
       " , candidates {\n",
       "   content {\n",
       "     role: \"model\"\n",
       "     parts {\n",
       "       text: \"As an AI, I don\\'t have feelings or experiences like humans do. So, I\\'m not \\\"feeling\\\" anything in the way you might be. But I\\'m\"\n",
       "     }\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_HATE_SPEECH\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.12109375\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.056640625\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.0415039062\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0194091797\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_HARASSMENT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.150390625\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0903320312\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.263671875\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.161132812\n",
       "   }\n",
       " }\n",
       " model_version: \"gemini-1.5-flash\"\n",
       " , candidates {\n",
       "   content {\n",
       "     role: \"model\"\n",
       "     parts {\n",
       "       text: \"As an AI, I don\\'t have feelings or experiences like humans do. So, I\\'m not \\\"feeling\\\" anything in the way you might be. But I\\'m here and ready to assist you with any questions or tasks you may have! 😊 What can I help you with today? \\n\"\n",
       "     }\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_HATE_SPEECH\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.0737304688\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0368652344\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.0311279297\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0203857422\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_HARASSMENT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.0708007812\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0361328125\n",
       "   }\n",
       "   safety_ratings {\n",
       "     category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "     probability: NEGLIGIBLE\n",
       "     probability_score: 0.235351562\n",
       "     severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "     severity_score: 0.0756835938\n",
       "   }\n",
       " }\n",
       " model_version: \"gemini-1.5-flash\"\n",
       " , candidates {\n",
       "   content {\n",
       "     role: \"model\"\n",
       "     parts {\n",
       "       text: \"\"\n",
       "     }\n",
       "   }\n",
       "   finish_reason: STOP\n",
       " }\n",
       " model_version: \"gemini-1.5-flash\"\n",
       " usage_metadata {\n",
       "   prompt_token_count: 7\n",
       "   candidates_token_count: 63\n",
       "   total_token_count: 70\n",
       " }\n",
       " ])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# async stream\n",
    "response = gemini_vertexai.astream(prompt, model_name=\"gemini-1.5-flash\")\n",
    "[r async for r in response]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple resposne generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = gemini_vertexai.run(prompt, n_results=2, model_name=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"As a large language model, I don't have feelings or experiences like humans do. But I'm here and ready to assist you with any questions or tasks you may have! How can I help you today? 😊 \\n\"},\n",
       "  {'text': \"I am an AI language model, so I don't have feelings like humans do. However, I am here to assist you with any questions or tasks you may have! How can I help you today? 😊 \\n\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [{'text': \"As an AI, I don't have feelings or experiences like humans do. However, I'm here and ready to assist you with any questions or tasks you may have! How can I help you today? 😊 \\n\"},\n",
       "  {'text': \"I am an AI language model, so I don't have feelings or experiences like humans do. However, I am here to assist you with any questions or tasks you may have! How can I help you today? 😊 \\n\"}],\n",
       " 'name': None}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# async multiple generation\n",
    "response = await gemini_vertexai.arun(prompt, n_results=2, model_name=\"gemini-1.5-flash\")\n",
    "response.message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Claude on Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = ClaudeFunctionalChat(api_key_env_name=\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready to assist you with any questions or tasks you may have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response = claude.run(prompt, model_name=\"claude-3-5-sonnet-20240620\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready to assist you with any questions or tasks you may have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# async\n",
    "response = await claude.arun(prompt, model_name=\"claude-3-5-sonnet-20240620\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming generation have not been supported yet by `ClaudeFunctionalChat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello! As')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text='Hello! As an AI language')], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't have\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't have feelings\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't have feelings,\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't have feelings, but I'm functioning\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't have feelings, but I'm functioning well an\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready to assist you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready to assist you with\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready to assist you with any questions or tasks you\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready to assist you with any questions or tasks you may have. How can\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready to assist you with any questions or tasks you may have. How can I help you today?\")], name=None), usage=Usage(prompt_tokens=0, completion_tokens=0, total_tokens=0), prompt=[{}], raw=None),\n",
       " CompletionResults(message=Message(role='assistant', content=[TextContent(text=\"Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready to assist you with any questions or tasks you may have. How can I help you today?\")], name=None), usage=Usage(prompt_tokens=14, completion_tokens=44, total_tokens=58), prompt=[{'role': 'user', 'content': [{'text': 'Hello. How are you today?', 'type': 'text'}]}], raw=[RawMessageStartEvent(message=Message(id='msg_01HkgFWfwEByCcbhpRWNGA4q', content=[], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason=None, stop_sequence=None, type='message', usage=Usage(input_tokens=14, output_tokens=1)), type='message_start'), RawContentBlockStartEvent(content_block=TextBlock(text='', type='text'), index=0, type='content_block_start'), RawContentBlockDeltaEvent(delta=TextDelta(text='Hello', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text='! As', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text=' an AI language', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text=\" model, I don't\", type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text=' have', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text=' feelings', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text=',', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text=\" but I'm functioning\", type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text=' well an', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text='d ready', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text=' to assist you', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text=' with', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text=' any questions or tasks you', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text=' may have. How can', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockDeltaEvent(delta=TextDelta(text=' I help you today?', type='text_delta'), index=0, type='content_block_delta'), RawContentBlockStopEvent(index=0, type='content_block_stop'), RawMessageDeltaEvent(delta=Delta(stop_reason='end_turn', stop_sequence=None), type='message_delta', usage=MessageDeltaUsage(output_tokens=43)), RawMessageStopEvent(type='message_stop')])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = list(claude.chat.stream(prompt, model_name=\"claude-3-5-sonnet-20240620\"))\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RawMessageStartEvent(message=Message(id='msg_01HkgFWfwEByCcbhpRWNGA4q', content=[], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason=None, stop_sequence=None, type='message', usage=Usage(input_tokens=14, output_tokens=1)), type='message_start'),\n",
       " RawContentBlockStartEvent(content_block=TextBlock(text='', type='text'), index=0, type='content_block_start'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text='Hello', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text='! As', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text=' an AI language', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text=\" model, I don't\", type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text=' have', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text=' feelings', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text=',', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text=\" but I'm functioning\", type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text=' well an', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text='d ready', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text=' to assist you', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text=' with', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text=' any questions or tasks you', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text=' may have. How can', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockDeltaEvent(delta=TextDelta(text=' I help you today?', type='text_delta'), index=0, type='content_block_delta'),\n",
       " RawContentBlockStopEvent(index=0, type='content_block_stop'),\n",
       " RawMessageDeltaEvent(delta=Delta(stop_reason='end_turn', stop_sequence=None), type='message_delta', usage=MessageDeltaUsage(output_tokens=43)),\n",
       " RawMessageStopEvent(type='message_stop')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[-1].raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Claude on Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_bedrock = ClaudeFunctionalChat(\n",
    "    api_type=\"bedrock\",\n",
    "    aws_access_key_env_name=\"AWS_ACCESS_KEY\",\n",
    "    aws_secret_key_env_name=\"AWS_SECRET_KEY\",\n",
    "    aws_region_env_name=\"AWS_REGION\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! As an AI language model, I don't have personal feelings or physical sensations, but I'm operating properly and ready to assist you with any questions or tasks you might have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response = claude_bedrock.run(prompt, model_name=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_bdrk_01WsgkdRKm5gBnxpwn45EBJK', content=[TextBlock(text=\"Hello! As an AI language model, I don't have personal feelings or physical sensations, but I'm operating properly and ready to assist you with any questions or tasks you might have. How can I help you today?\", type='text')], model='claude-3-sonnet-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=14, output_tokens=48))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! As an AI language model, I don't have feelings or emotions, but I'm functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response = await claude_bedrock.arun(prompt, model_name=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal message system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langrila's chat module transforms user prompt and conversation history to universal message object at first, then converts to each client message. Conversation memory has history with universal message format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hello, how are you today?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting from prompt to universal message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='user', content=[TextContent(text='Hello, how are you today?')], name=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langrila.openai import OpenAIMessage\n",
    "\n",
    "universal_message = OpenAIMessage.to_universal_message(role=\"user\", message=prompt)\n",
    "universal_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting from universal message to client message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': [{'type': 'text', 'text': 'Hello, how are you today?'}],\n",
       " 'name': 'User'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OpenAIMessage.to_client_message(universal_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini module has same interface. Also Claude as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='user', content=[TextContent(text='Hello, how are you today?')], name=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langrila.gemini.genai import GeminiMessage\n",
    "\n",
    "# same method as that of OpenAIMessage\n",
    "universal_message = GeminiMessage.to_universal_message(role=\"user\", message=prompt)\n",
    "universal_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parts {\n",
       "  text: \"Hello, how are you today?\"\n",
       "}\n",
       "role: \"user\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GeminiMessage.to_client_message(universal_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to set a role and name for your prompt, Message class allows you to do it. Raw text prompt is converted to TextContent object in langrila's chat modules, so TextContent object also can be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='user', content=[TextContent(text='Hello.')], name='Nsak')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langrila import Message\n",
    "\n",
    "prompt = Message(role=\"user\", content=\"Hello.\", name=\"Nsak\")\n",
    "universal_message = OpenAIMessage.to_universal_message(role=\"user\", message=prompt)\n",
    "universal_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to specify system instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langrila's module accepts system instruction as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For OpenAI Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"You must answer any question only with Yes or No.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_openai = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"API_KEY\",\n",
    "    conversation_memory=InMemoryConversationMemory(),  # just for the explanation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Please tell me about how to sleep well.\"\n",
    "response = chat_openai.run(\n",
    "    prompt=prompt,\n",
    "    model_name=\"gpt-4o-2024-08-06\",\n",
    "    system_instruction=system_instruction,\n",
    ")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System prompt is not stored into conversation memory but it exists in prompt attribute in response object. It's bacause we can make system prompt replaceable flexibly. System prompt is inserted as a first message just before API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': {'role': 'assistant', 'content': [{'text': 'No.'}], 'name': None},\n",
       " 'usage': {'model_name': 'gpt-4o-2024-08-06',\n",
       "  'prompt_tokens': 34,\n",
       "  'completion_tokens': 2},\n",
       " 'prompt': [{'role': 'system',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'You must answer any question only with Yes or No.'}],\n",
       "   'name': 'System'},\n",
       "  {'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Please tell me about how to sleep well.'}],\n",
       "   'name': 'User'}]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see system prompt in the prompt attribute in the response\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': [{'text': 'Please tell me about how to sleep well.'}],\n",
       "  'name': None},\n",
       " {'role': 'assistant', 'content': [{'text': 'No.'}], 'name': None}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# System prompt is not shown in the conversation memory\n",
    "chat_openai.conversation_memory.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini and Claude also accept system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = GeminiFunctionalChat(api_key_env_name=\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Please tell me about how to sleep well.\"\n",
    "response = gemini.run(\n",
    "    prompt=prompt, model_name=\"gemini-1.5-pro\", system_instruction=system_instruction\n",
    ")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': {'role': 'assistant',\n",
       "  'content': [{'text': 'No. \\n'}],\n",
       "  'name': None},\n",
       " 'usage': {'model_name': 'gemini-1.5-pro',\n",
       "  'prompt_tokens': 21,\n",
       "  'completion_tokens': 2},\n",
       " 'prompt': [parts {\n",
       "    text: \"Please tell me about how to sleep well.\"\n",
       "  }\n",
       "  role: \"user\"]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = ClaudeFunctionalChat(api_key_env_name=\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Please tell me about how to sleep well.\"\n",
    "response = claude.run(\n",
    "    prompt=prompt, model_name=\"claude-3-5-sonnet-20240620\", system_instruction=system_instruction\n",
    ")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': {'role': 'assistant', 'content': [{'text': 'Yes.'}], 'name': None},\n",
       " 'usage': {'model_name': 'claude-3-5-sonnet-20240620',\n",
       "  'prompt_tokens': 27,\n",
       "  'completion_tokens': 5},\n",
       " 'prompt': [{'role': 'user',\n",
       "   'content': [{'text': 'Please tell me about how to sleep well.',\n",
       "     'type': 'text'}]}]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For OpenAI Chat Completion, # of tokens is calculated before API call, and module truncates prompt automatically to make sure # of tokens meets token limitation. In this section, we simulate this truncation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conventional way is deprecated and removed in future version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DeprecationWarning]: context_length in __init__() will be deprecated since 0.4.0 and will be removed in version 1.0.0 for OpenAIChatModule. Use 'conversation_length_adjuster' instead. For more details, see: Token management section in langrila/notebooks/01.introduction.ipynb.\n",
      "[DeprecationWarning]: context_length in __init__() will be deprecated since 0.4.0 and will be removed in version 1.0.0 for OpenAIFunctionCallingModule. Use 'conversation_length_adjuster' instead. For more details, see: Token management section in langrila/notebooks/01.introduction.ipynb.\n"
     ]
    }
   ],
   "source": [
    "chat_openai = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"API_KEY\",\n",
    "    api_type=\"openai\",\n",
    "    model_name=\"gpt-4o-2024-08-06\",\n",
    "    context_length=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please specify conversation_length_adjuster instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_openai = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"API_KEY\",\n",
    "    conversation_memory=InMemoryConversationMemory(),  # just for the explanation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input message is truncated because total length of messages exceeds context length.\n"
     ]
    }
   ],
   "source": [
    "from langrila.openai import OldConversationTruncationModule\n",
    "\n",
    "prompts = [\n",
    "    \"Please tell me about a bird called Kiji in Japan.\",\n",
    "    \"What does Kiji do in the tale of the Momotaro\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = chat_openai.run(\n",
    "        prompt,\n",
    "        model_name=\"gpt-4o-2024-08-06\",\n",
    "        conversation_length_adjuster=OldConversationTruncationModule(\n",
    "            model_name=\"gpt-4o-2024-08-06\", context_length=200\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old conversation was truncated as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=199, completion_tokens=229, total_tokens=428)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE : Usage after truncation might slightly be different from the specified context_length\n",
    "response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': ': The Green Pheasant holds cultural importance in Japan and is considered a national bird of the country. It has been featured in Japanese art, literature, and folklore. The call of the male Kiji is also associated with the arrival of spring.\\n\\n4. **Behavior**: Green Pheasants are ground-dwelling birds that are known for their strong legs and ability to run quickly. They are also capable of short, rapid flights if startled. Their diet mainly consists of seeds, insects, and small animals.\\n\\n5. **Role in Ecosystem**: As a part of the ecosystem, they contribute to seed dispersion and also serve as prey for larger predators.\\n\\nIn summary, the Kiji or Green Pheasant is a distinctive and culturally significant bird in Japan, admired for its beautiful plumage and adaptation to various habitats across the country.'}],\n",
       "  'name': 'Assistant'},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'What does Kiji do in the tale of the Momotaro'}],\n",
       "  'name': 'User'}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But truncation does not affect conversation memory itself. You can see full conversation history in the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': [{'text': 'Please tell me about a bird called Kiji in Japan.'}],\n",
       "  'name': None},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'text': 'The \"Kiji\" refers to the Green Pheasant, known in Japanese as \"Kijī\" (キジ or 雉). This bird, scientifically named *Phasianus versicolor*, is native to Japan and is notable for its vibrant plumage. It is considered a subspecies of the Common Pheasant (*Phasianus colchicus*), although sometimes it is regarded as a separate species.\\n\\nHere are some key points about the Green Pheasant:\\n\\n1. **Appearance**: Male Green Pheasants are particularly striking, with iridescent green plumage on their breasts and upper body, a bluish-purple neck, and distinctive red facial wattles. Females are more subdued in color, with mottled brown plumage that provides camouflage.\\n\\n2. **Habitat**: These birds are commonly found in various habitats across Japan, including forests, grasslands, and farmlands. They are adaptable and can often be seen at the edges of woodlands and in areas with dense undergrowth.\\n\\n3. **Cultural Significance**: The Green Pheasant holds cultural importance in Japan and is considered a national bird of the country. It has been featured in Japanese art, literature, and folklore. The call of the male Kiji is also associated with the arrival of spring.\\n\\n4. **Behavior**: Green Pheasants are ground-dwelling birds that are known for their strong legs and ability to run quickly. They are also capable of short, rapid flights if startled. Their diet mainly consists of seeds, insects, and small animals.\\n\\n5. **Role in Ecosystem**: As a part of the ecosystem, they contribute to seed dispersion and also serve as prey for larger predators.\\n\\nIn summary, the Kiji or Green Pheasant is a distinctive and culturally significant bird in Japan, admired for its beautiful plumage and adaptation to various habitats across the country.'}],\n",
       "  'name': None},\n",
       " {'role': 'user',\n",
       "  'content': [{'text': 'What does Kiji do in the tale of the Momotaro'}],\n",
       "  'name': None},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'text': \"In the Japanese folktale of Momotaro, the Kiji, or pheasant, plays a crucial role as one of Momotaro's animal companions. The story follows Momotaro, a boy born from a peach, who sets out on a journey to defeat a band of ogres (oni) that have been terrorizing his village. On his journey, Momotaro befriends three animals who assist him in his quest: a dog, a monkey, and a pheasant (Kiji).\\n\\nThe Kiji contributes significantly to the team with its ability to fly, providing a strategic advantage. In the tale, the Kiji often scouts ahead, gathering information about the ogres' location and their stronghold. It also helps in attacking the ogres from the air, using its agility and speed to outmaneuver the enemies.\\n\\nTogether with the other animals and Momotaro's leadership, the Kiji helps in the successful defeat of the ogres, allowing Momotaro to return home as a hero with the ogres' treasure. The story highlights themes of cooperation, bravery, and the importance of friendship and teamwork.\"}],\n",
       "  'name': None}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_openai.conversation_memory.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If prompts contain some images and # of tokens exceeds limitation, image might be truncated entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage gathering across multiple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage object allows you to sum multiple usages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=300, completion_tokens=150, total_tokens=450)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage1 = Usage(model_name=\"gpt-4o-2024-05-13\", prompt_tokens=100, completion_tokens=50)\n",
    "\n",
    "usage2 = Usage(model_name=\"gpt-4o-2024-05-13\", prompt_tokens=200, completion_tokens=100)\n",
    "\n",
    "usage1 + usage2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage don't have capability to sum usages from different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error!\n"
     ]
    }
   ],
   "source": [
    "usage3 = Usage(model_name=\"gpt-4o-mini-2024-07-18\", prompt_tokens=300, completion_tokens=150)\n",
    "\n",
    "try:\n",
    "    usage1 + usage3  # Error\n",
    "except:\n",
    "    print(\"Error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But usage with empty model_name is added to any other usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=200, completion_tokens=100, total_tokens=300)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage4 = Usage(prompt_tokens=100, completion_tokens=50)\n",
    "\n",
    "usage1 + usage4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, it's not possible to add usage to usage of empty model_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    usage4 + usage1\n",
    "except:\n",
    "    print(\"Error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function, we sometimes want to sum up total #of tokens over each models. In langrila, shared token counter is available to integrate total usage from multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langrila import TokenCounter\n",
    "\n",
    "shared_memory = InMemoryConversationMemory()  # just for the explanation\n",
    "\n",
    "shared_token_counter = TokenCounter()\n",
    "\n",
    "gemini = GeminiFunctionalChat(\n",
    "    api_key_env_name=\"GEMINI_API_KEY\",\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    conversation_memory=shared_memory,\n",
    "    token_counter=shared_token_counter,\n",
    ")\n",
    "\n",
    "chat_openai = OpenAIFunctionalChat(\n",
    "    api_key_env_name=\"API_KEY\",\n",
    "    model_name=\"gpt-4o-2024-05-13\",\n",
    "    api_type=\"openai\",\n",
    "    conversation_memory=shared_memory,\n",
    "    token_counter=shared_token_counter,\n",
    ")\n",
    "\n",
    "claude = ClaudeFunctionalChat(\n",
    "    model_name=\"claude-3-5-sonnet-20240620\",\n",
    "    api_key_env_name=\"ANTHROPIC_API_KEY\",\n",
    "    conversation_memory=shared_memory,\n",
    "    token_counter=shared_token_counter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"What is the pheasant?\",\n",
    "    \"Please tell me about a bird called Kiji in Japan.\",\n",
    "    \"What does Kiji do in the tale of the Momotaro\",\n",
    "]\n",
    "\n",
    "clients = [gemini, chat_openai, claude]\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    client = clients[i]\n",
    "    response = client.run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-1.5-flash': Usage(prompt_tokens=6, completion_tokens=376, total_tokens=382), 'gpt-4o-2024-05-13': Usage(prompt_tokens=438, completion_tokens=474, total_tokens=912), 'claude-3-5-sonnet-20240620': Usage(prompt_tokens=1018, completion_tokens=457, total_tokens=1475)}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_token_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manage a typical prompt as a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# INSTRUCTION\n",
      "{instruction}\n",
      "\n",
      "# TEXT\n",
      "{text}\n"
     ]
    }
   ],
   "source": [
    "template = PromptTemplate.from_text_file(\"../data/sample_prompt_template.txt\")\n",
    "print(template.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(args={'instruction': 'Hello', 'text': 'world!'}, template='# INSTRUCTION\\n{instruction}\\n\\n# TEXT\\n{text}')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.set_args(instruction=\"Hello\", text=\"world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# INSTRUCTION\n",
      "Hello\n",
      "\n",
      "# TEXT\n",
      "world!\n"
     ]
    }
   ],
   "source": [
    "print(template.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass template string to PromptTemplate directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(args={}, template='# INSTRUCTION\\n{instruction}\\n\\n# TEXT\\n{text}')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PromptTemplate(template=\"# INSTRUCTION\\n{instruction}\\n\\n# TEXT\\n{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
